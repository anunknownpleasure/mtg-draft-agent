{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb501a82",
   "metadata": {},
   "source": [
    "## MTG Transformer Decoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccae05c",
   "metadata": {},
   "source": [
    "#### Importing data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8d0e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from .gz:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expansion</th>\n",
       "      <th>event_type</th>\n",
       "      <th>draft_id</th>\n",
       "      <th>draft_time</th>\n",
       "      <th>rank</th>\n",
       "      <th>event_match_wins</th>\n",
       "      <th>event_match_losses</th>\n",
       "      <th>pack_number</th>\n",
       "      <th>pick_number</th>\n",
       "      <th>pick</th>\n",
       "      <th>...</th>\n",
       "      <th>pool_Yuna, Hope of Spira</th>\n",
       "      <th>pool_Yuriko, the Tiger's Shadow</th>\n",
       "      <th>pool_Zack Fair</th>\n",
       "      <th>pool_Zanarkand, Ancient Metropolis</th>\n",
       "      <th>pool_Zell Dincht</th>\n",
       "      <th>pool_Zenos yae Galvus</th>\n",
       "      <th>pool_Zidane, Tantalus Thief</th>\n",
       "      <th>pool_Zodiark, Umbral God</th>\n",
       "      <th>user_n_games_bucket</th>\n",
       "      <th>user_game_win_rate_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIN</td>\n",
       "      <td>TradDraft</td>\n",
       "      <td>d5b5f363128e4ca79031384c95e11f01</td>\n",
       "      <td>2025-06-10 23:54:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dragoon's Lance</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIN</td>\n",
       "      <td>TradDraft</td>\n",
       "      <td>d5b5f363128e4ca79031384c95e11f01</td>\n",
       "      <td>2025-06-10 23:54:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Freya Crescent</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIN</td>\n",
       "      <td>TradDraft</td>\n",
       "      <td>d5b5f363128e4ca79031384c95e11f01</td>\n",
       "      <td>2025-06-10 23:54:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dragoon's Lance</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIN</td>\n",
       "      <td>TradDraft</td>\n",
       "      <td>d5b5f363128e4ca79031384c95e11f01</td>\n",
       "      <td>2025-06-10 23:54:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>G'raha Tia</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIN</td>\n",
       "      <td>TradDraft</td>\n",
       "      <td>d5b5f363128e4ca79031384c95e11f01</td>\n",
       "      <td>2025-06-10 23:54:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Delivery Moogle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  expansion event_type                          draft_id           draft_time  \\\n",
       "0       FIN  TradDraft  d5b5f363128e4ca79031384c95e11f01  2025-06-10 23:54:18   \n",
       "1       FIN  TradDraft  d5b5f363128e4ca79031384c95e11f01  2025-06-10 23:54:18   \n",
       "2       FIN  TradDraft  d5b5f363128e4ca79031384c95e11f01  2025-06-10 23:54:18   \n",
       "3       FIN  TradDraft  d5b5f363128e4ca79031384c95e11f01  2025-06-10 23:54:18   \n",
       "4       FIN  TradDraft  d5b5f363128e4ca79031384c95e11f01  2025-06-10 23:54:18   \n",
       "\n",
       "   rank  event_match_wins  event_match_losses  pack_number  pick_number  \\\n",
       "0   NaN                 1                   2            0            0   \n",
       "1   NaN                 1                   2            0            1   \n",
       "2   NaN                 1                   2            0            2   \n",
       "3   NaN                 1                   2            0            3   \n",
       "4   NaN                 1                   2            0            4   \n",
       "\n",
       "              pick  ...  pool_Yuna, Hope of Spira  \\\n",
       "0  Dragoon's Lance  ...                         0   \n",
       "1   Freya Crescent  ...                         0   \n",
       "2  Dragoon's Lance  ...                         0   \n",
       "3       G'raha Tia  ...                         0   \n",
       "4  Delivery Moogle  ...                         0   \n",
       "\n",
       "   pool_Yuriko, the Tiger's Shadow  pool_Zack Fair  \\\n",
       "0                                0               0   \n",
       "1                                0               0   \n",
       "2                                0               0   \n",
       "3                                0               0   \n",
       "4                                0               0   \n",
       "\n",
       "   pool_Zanarkand, Ancient Metropolis  pool_Zell Dincht  \\\n",
       "0                                   0                 0   \n",
       "1                                   0                 0   \n",
       "2                                   0                 0   \n",
       "3                                   0                 0   \n",
       "4                                   0                 0   \n",
       "\n",
       "   pool_Zenos yae Galvus  pool_Zidane, Tantalus Thief  \\\n",
       "0                      0                            0   \n",
       "1                      0                            0   \n",
       "2                      0                            0   \n",
       "3                      0                            0   \n",
       "4                      0                            0   \n",
       "\n",
       "   pool_Zodiark, Umbral God  user_n_games_bucket  user_game_win_rate_bucket  \n",
       "0                         0                  100                       0.58  \n",
       "1                         0                  100                       0.58  \n",
       "2                         0                  100                       0.58  \n",
       "3                         0                  100                       0.58  \n",
       "4                         0                  100                       0.58  \n",
       "\n",
       "[5 rows x 740 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip as gz\n",
    "\n",
    "file_path = 'C:/Users/arpit/Downloads/draft_data_public.FIN.TradDraft.csv.gz'\n",
    "\n",
    "\n",
    "try:\n",
    "    # Open the .gz file in read binary mode\n",
    "    with gz.open(file_path, 'rt', encoding='utf-8') as gz_file:\n",
    "        # Now you can read from gz_file just like a regular file.\n",
    "        # For example, if it's a CSV, you can read it with pandas:\n",
    "        df = pd.read_csv(gz_file)\n",
    "\n",
    "        print(\"DataFrame loaded from .gz:\")\n",
    "        display(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: .gz file not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169547e",
   "metadata": {},
   "source": [
    "#### Getting card names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "287c9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df.columns.tolist()\n",
    "\n",
    "\n",
    "pack_columns = [col for col in df.columns if col.startswith('pack_card_')]\n",
    "pick_columns = [col for col in df.columns if col.startswith('pool_')]\n",
    "\n",
    "cards = [col.replace(\"pack_card_\", \"\") for col in pack_columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff46bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866a28d",
   "metadata": {},
   "source": [
    "#### Card to number mapping:\n",
    "\n",
    "We tokenize cards by assigning a number to each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3f954df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_card_to_id_mapping(card_names):\n",
    "  \"\"\"\n",
    "  Creates a dictionary mapping card names to unique integer IDs.\n",
    "\n",
    "  Args:\n",
    "    card_names: A list of unique card names (strings).\n",
    "\n",
    "  Returns:\n",
    "    A dictionary where keys are card names and values are unique integer IDs.\n",
    "  \"\"\"\n",
    "  card_to_id = {name: i+1 for i, name in enumerate(card_names)}\n",
    "  return card_to_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0132d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep: \n",
    "\n",
    "# We need to convert the data in the following way. After each card has a token, we need to make 13 x 13 x 1 tensor. \n",
    "# Where first 13 are the cards available to pick from, next are cards in hand and last is the card chosen in that round. \n",
    "\n",
    "# Helper functions: From a row, take the one hot encoded pack data, pick data and choice and convert to a pytorch tensor\n",
    "\n",
    "tokens_pack = create_card_to_id_mapping(pack_columns)\n",
    "tokens_pool = create_card_to_id_mapping(pick_columns)\n",
    "tokens = create_card_to_id_mapping(cards)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b1b96",
   "metadata": {},
   "source": [
    "#### Tokenizing rows\n",
    "\n",
    "For every row, we construct a tensor of tokens of pack and pick data which is then padded to maintain uniform sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "369d8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def tokenizer(row, pad_len=40, pad_val=0):\n",
    "    # Collect tokens for pack and pick from the row\n",
    "    pack_token = []\n",
    "    pick_token = []\n",
    "\n",
    "    for col in pack_columns:\n",
    "        if row[col] == 1:\n",
    "            pack_token.append(torch.tensor([tokens_pack[col]], dtype=torch.long))\n",
    "\n",
    "    for col in pick_columns:\n",
    "        if row[col] == 1:\n",
    "            pick_token.append(torch.tensor([tokens_pool[col]], dtype=torch.long))\n",
    "\n",
    "    # Helper to pad a list of 1D tensors to fixed length pad_len\n",
    "    def pad_to_fixed(tensor_list, length, pad_value):\n",
    "        if len(tensor_list) == 0:\n",
    "            # if empty, return all padding\n",
    "            return torch.full((length,), pad_value, dtype=torch.long)\n",
    "        # concatenate tokens into one 1D tensor\n",
    "        combined = torch.cat(tensor_list)\n",
    "        if combined.size(0) < length:\n",
    "            pad_amount = length - combined.size(0)\n",
    "            combined = F.pad(combined, (0, pad_amount), value=pad_value)\n",
    "        else:\n",
    "            combined = combined[:length]\n",
    "        return combined\n",
    "\n",
    "    padded_picks = pad_to_fixed(pick_token, pad_len, pad_val)\n",
    "    padded_packs = pad_to_fixed(pack_token, pad_len, pad_val)\n",
    "\n",
    "     \n",
    "    final_tensor = torch.stack([padded_packs, padded_picks], dim=0)\n",
    "\n",
    "    \n",
    "\n",
    "    picked_card = row['pick']\n",
    "    \n",
    "    picked_card_token = torch.tensor([tokens[picked_card]], dtype=torch.long)\n",
    "    \n",
    "\n",
    "    return final_tensor, picked_card_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bcb778f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.apply(lambda row: tokenizer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252feea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "for input_tensor, label_tensor in data:\n",
    "    inputs.append(input_tensor)  # shape (2, pad_len)\n",
    "    labels.append(label_tensor)  # shape (1,)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "inputs, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "pack_train = torch.stack([x[0] for x in X_train])   # x[0] is the \"pack\" part (shape: pad_len)\n",
    "pool_train = torch.stack([x[1] for x in X_train])\n",
    "pack_test = torch.stack([x[0] for x in X_test])   # x[0] is the \"pack\" part (shape: pad_len)\n",
    "pool_test = torch.stack([x[1] for x in X_test]) \n",
    "labels_train = torch.stack(y_train).squeeze()\n",
    "labels_test = torch.stack(y_test).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Hyperparameters\n",
    "\n",
    "\n",
    "VOCAB_SIZE = len(pack_columns)+1  # Number of unique cards\n",
    "SEQ_LEN = 40\n",
    "BATCH_SIZE = 32\n",
    "EMBED_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "NHEAD = 4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f6315",
   "metadata": {},
   "source": [
    "#### Decoder sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "36723404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, nhead, pad_idx = 0 , embed_dim = 128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(embed_dim, nhead)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=2)\n",
    "        self.output = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, pack_tensor, pool_tensor):\n",
    "        \n",
    "        tgt = self.embedding(pack_tensor).permute(1, 0, 2)  # (seq_len, batch, d_model) \n",
    "        memory = self.embedding(pool_tensor).permute(1,0,2)\n",
    "        \n",
    "        sz = tgt.size(0)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(sz).to(pack_tensor.device)\n",
    "\n",
    "        \n",
    "        out = self.decoder(tgt, memory, tgt_mask=tgt_mask)\n",
    "        out = self.output(out[-1])  # predict last token only\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acecf36",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "02249b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.9181\n",
      "Epoch 2: Loss = 1.5117\n",
      "Epoch 3: Loss = 1.4267\n",
      "Epoch 4: Loss = 1.3787\n",
      "Epoch 5: Loss = 1.3485\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(pack_train, pool_train, labels_train)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model = DraftDecoder(VOCAB_SIZE, SEQ_LEN, NHEAD).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        for pack_token, pool_token,target in loader:\n",
    "            pack_token = pack_token.to(DEVICE)\n",
    "            pool_token = pool_token.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "\n",
    "            logits = model(pack_token, pool_token)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(loader):.4f}\")\n",
    "\n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
