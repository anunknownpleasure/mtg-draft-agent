{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Drive or Jupyter notebook -- only runs when first loaded\n",
    "if \"CONFIG_DONE\" not in globals():\n",
    "    # Need to mount drive and clone repo to access data and functions\n",
    "    try:\n",
    "        from google.colab import drive  # type: ignore\n",
    "\n",
    "        IN_COLAB = True\n",
    "\n",
    "        # clone repo\n",
    "        !git clone https://github.com/doctorsmylie/mtg-draft-agent\n",
    "        %cd mtg-draft-agent\n",
    "\n",
    "    except ModuleNotFoundError:\n",
    "        IN_COLAB = False\n",
    "\n",
    "    # Finish configuration -- also configures notebook outside of Colab\n",
    "    %run \"project_path.ipynb\"\n",
    "else:\n",
    "    print(\"Config done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from datasets import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import pathlib\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import functions.card_io as card_io\n",
    "import functions.utils as utils\n",
    "\n",
    "# Setting device on GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drafts = pd.read_parquet('/content/drive/MyDrive/DSK_PremierDraft_drafts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09145659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bots.lstm_bot import *\n",
    "\n",
    "# Model, Loss and Optimizer\n",
    "embed_dim = 128 #64\n",
    "hidden_dim = 256 #128\n",
    "num_layers = 2\n",
    "p_LSTM = 0.3\n",
    "p_out = 0.5\n",
    "model = DraftBotLSTM(\n",
    "    vocab_size, embed_dim, hidden_dim, num_layers=num_layers, p_LSTM=p_LSTM, p_out=p_out\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split players into train/val/test\n",
    "draft_ids = drafts[\"draft_id\"].unique()\n",
    "\n",
    "train_ids, temp_ids = train_test_split(draft_ids, test_size=0.2, random_state=304)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=304)\n",
    "\n",
    "# Split Dataframe\n",
    "drafts_train = drafts[drafts[\"draft_id\"].isin(train_ids)]\n",
    "drafts_val = drafts[drafts[\"draft_id\"].isin(val_ids)]\n",
    "drafts_test = drafts[drafts[\"draft_id\"].isin(test_ids)]\n",
    "\n",
    "# Create custom Datasets for each split\n",
    "dataset_train = PlayerDataset(drafts_train)\n",
    "dataset_val = PlayerDataset(drafts_val)\n",
    "dataset_test = PlayerDataset(drafts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d18fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom DataLoaders\n",
    "dlss = []\n",
    "for dataset in [dataset_train, dataset_val, dataset_test]:\n",
    "    dls = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_player_turns\n",
    "    )\n",
    "    dlss.append(dls)\n",
    "\n",
    "dls_train, dls_val, dls_test = dlss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop parameters\n",
    "num_epochs = 25\n",
    "num_turns = dataset_train.num_turns()\n",
    "\n",
    "train_losses = torch.zeros(num_epochs)\n",
    "val_losses = torch.zeros(num_epochs)\n",
    "\n",
    "train_accuracies = torch.zeros((num_epochs, num_turns))\n",
    "val_accuracies = torch.zeros((num_epochs, num_turns))\n",
    "\n",
    "# Back propagate over the whole game\n",
    "# If we omit this line, we back propagate over a single round of the draft\n",
    "# (i.e. over 14 turns)\n",
    "chunk_size = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_accuracy_epoch = train_epoch(\n",
    "        model, dls_train, optimizer, loss_fn, chunk_size=None, device=device\n",
    "    )\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy_epoch = evaluate(model, dls_val, loss_fn, device=device)\n",
    "\n",
    "    # Print results\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    train_losses[epoch] = train_loss\n",
    "    val_losses[epoch] = val_loss\n",
    "\n",
    "    train_accuracies[epoch, :] = train_accuracy_epoch.cpu()\n",
    "    val_accuracies[epoch, :] = val_accuracy_epoch.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455775d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of random choice\n",
    "tt = np.arange(14, dtype=float)\n",
    "prob_random = 1 / np.flip(tt + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train\", marker=\".\")\n",
    "plt.plot(val_losses, label=\"Val\", marker=\".\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Losses\")\n",
    "\n",
    "y_max = plt.ylim()[1]\n",
    "y_max = utils.ceil_digit(y_max, digits=2)\n",
    "plt.ylim(0, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate packs\n",
    "plt.axvline(max_pack_size - 1, color=\"red\")\n",
    "plt.axvline(2 * max_pack_size - 1, color=\"red\")\n",
    "\n",
    "# Plot probability of random choice\n",
    "plt.plot(tt, prob_random, \"--\", color=\"blue\", label=\"Chance\")\n",
    "plt.plot(14 * 1 + tt, prob_random, \"--\", color=\"blue\")\n",
    "plt.plot(14 * 2 + tt, prob_random, \"--\", color=\"blue\")\n",
    "\n",
    "epoch = -1\n",
    "plt.plot(\n",
    "    train_accuracies[epoch, :], label=\"Train\", marker=\".\", markersize=15, color=\"orange\"\n",
    ")\n",
    "plt.plot(\n",
    "    val_accuracies[epoch, :], label=\"Val\", marker=\".\", markersize=10, color=\"green\"\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Turn\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracies per Turn\")\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d433f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_models/lstm_params.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
